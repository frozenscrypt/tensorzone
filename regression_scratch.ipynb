{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating inputs\n",
    "X = [(i,2*i) for i in range(500)]\n",
    "#Generating outputs\n",
    "Y = [(i + 2*i + 1) for i in range(500)]\n",
    "#Converting to numpy arrays to support efficient operations\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting into train and test data\n",
    "X_train = X[0:400,:]\n",
    "Y_train = Y[0:400]\n",
    "X_test = X[400:,:]\n",
    "Y_test = Y[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 2), (100, 2), (400,), (100,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch Size\n",
    "batch_size = 50\n",
    "#Number of batches\n",
    "num_batches = int(len(X_train)/batch_size)\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40977731,  0.50479349,  0.22971408]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weights and bias intitialization\n",
    "w = np.random.uniform(size = (1,3))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing output\n",
    "def output(x,w):\n",
    "    return np.add(np.matmul(w[:,0:2],x.T),w[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comnputing loss\n",
    "def losses(output, y):\n",
    "    return np.square(output - y.T).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List to store loss values on each training batch\n",
    "loss_values = []\n",
    "#Sum of losses for batches\n",
    "loss_sum = 0.0\n",
    "#Inital weight gradient\n",
    "dw = np.zeros(shape = (1,2))\n",
    "#Initial bias gradient\n",
    "db = 0.0\n",
    "#Learning rate\n",
    "learning_rate = 1e-9\n",
    "#Number of epochs\n",
    "n_epochs = 75\n",
    "#Batch indexing\n",
    "ind = 0\n",
    "#Loss per epoch\n",
    "loss_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 122754.2\n",
      "Loss at epoch 2: 98996.4\n",
      "Loss at epoch 3: 79836.8\n",
      "Loss at epoch 4: 64385.3\n",
      "Loss at epoch 5: 51924.3\n",
      "Loss at epoch 6: 41875.0\n",
      "Loss at epoch 7: 33770.6\n",
      "Loss at epoch 8: 27234.8\n",
      "Loss at epoch 9: 21963.9\n",
      "Loss at epoch 10: 17713.1\n",
      "Loss at epoch 11: 14285.0\n",
      "Loss at epoch 12: 11520.4\n",
      "Loss at epoch 13: 9290.9\n",
      "Loss at epoch 14: 7492.8\n",
      "Loss at epoch 15: 6042.8\n",
      "Loss at epoch 16: 4873.3\n",
      "Loss at epoch 17: 3930.2\n",
      "Loss at epoch 18: 3169.7\n",
      "Loss at epoch 19: 2556.3\n",
      "Loss at epoch 20: 2061.6\n",
      "Loss at epoch 21: 1662.7\n",
      "Loss at epoch 22: 1341.0\n",
      "Loss at epoch 23: 1081.5\n",
      "Loss at epoch 24: 872.2\n",
      "Loss at epoch 25: 703.5\n",
      "Loss at epoch 26: 567.4\n",
      "Loss at epoch 27: 457.6\n",
      "Loss at epoch 28: 369.1\n",
      "Loss at epoch 29: 297.7\n",
      "Loss at epoch 30: 240.1\n",
      "Loss at epoch 31: 193.7\n",
      "Loss at epoch 32: 156.3\n",
      "Loss at epoch 33: 126.1\n",
      "Loss at epoch 34: 101.7\n",
      "Loss at epoch 35:  82.1\n",
      "Loss at epoch 36:  66.2\n",
      "Loss at epoch 37:  53.4\n",
      "Loss at epoch 38:  43.1\n",
      "Loss at epoch 39:  34.8\n",
      "Loss at epoch 40:  28.1\n",
      "Loss at epoch 41:  22.7\n",
      "Loss at epoch 42:  18.3\n",
      "Loss at epoch 43:  14.8\n",
      "Loss at epoch 44:  12.0\n",
      "Loss at epoch 45:   9.7\n",
      "Loss at epoch 46:   7.9\n",
      "Loss at epoch 47:   6.4\n",
      "Loss at epoch 48:   5.2\n",
      "Loss at epoch 49:   4.2\n",
      "Loss at epoch 50:   3.4\n",
      "Loss at epoch 51:   2.8\n",
      "Loss at epoch 52:   2.3\n",
      "Loss at epoch 53:   1.9\n",
      "Loss at epoch 54:   1.5\n",
      "Loss at epoch 55:   1.3\n",
      "Loss at epoch 56:   1.1\n",
      "Loss at epoch 57:   0.9\n",
      "Loss at epoch 58:   0.7\n",
      "Loss at epoch 59:   0.6\n",
      "Loss at epoch 60:   0.5\n",
      "Loss at epoch 61:   0.5\n",
      "Loss at epoch 62:   0.4\n",
      "Loss at epoch 63:   0.4\n",
      "Loss at epoch 64:   0.3\n",
      "Loss at epoch 65:   0.3\n",
      "Loss at epoch 66:   0.3\n",
      "Loss at epoch 67:   0.2\n",
      "Loss at epoch 68:   0.2\n",
      "Loss at epoch 69:   0.2\n",
      "Loss at epoch 70:   0.2\n",
      "Loss at epoch 71:   0.2\n",
      "Loss at epoch 72:   0.2\n",
      "Loss at epoch 73:   0.2\n",
      "Loss at epoch 74:   0.2\n",
      "Loss at epoch 75:   0.2\n",
      "Loss at test time : 0.08892854423716305\n",
      "Final weights :  [[ 0.72637635  1.13799157  0.22973817]]\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for i in range(n_epochs):\n",
    "    for _ in range(num_batches):\n",
    "        #Splitting data into batches\n",
    "        X_batch = X_train[ind:ind + batch_size,:]\n",
    "        Y_batch = Y_train[ind:ind + batch_size]\n",
    "        #Computing output for batch\n",
    "        h = output(X_batch,w)\n",
    "        #Evaluating loss and adding to the batch sum\n",
    "        loss = losses(h,Y_batch)\n",
    "        loss_sum += loss\n",
    "        #Computing weight gradient \n",
    "        dw = np.matmul((h - Y_batch.T),X_batch)\n",
    "        #Computing bias gradient\n",
    "        db = (h - Y_batch.T).mean()\n",
    "        #Updating weights\n",
    "        w[:,0:2] -= learning_rate*dw\n",
    "        #Updating bias\n",
    "        w[:,2] -= learning_rate*db\n",
    "        #Setting ind to starting index of next batch\n",
    "        ind += batch_size\n",
    "    #Computing average loss per epoch\n",
    "    average_loss = loss_sum/num_batches\n",
    "    #Appending average loss to list of loss per epoch\n",
    "    loss_epoch.append(average_loss)\n",
    "    print(\"Loss at epoch {}: {:5.1f}\".format(i+1,average_loss))\n",
    "    #Resetting sum and average\n",
    "    loss_sum = 0.0\n",
    "    average_loss = 0.0\n",
    "    #Resetting ind for next epoch\n",
    "    ind = 0\n",
    "        \n",
    "#Testing\n",
    "#Compute output\n",
    "h = output(X_test, w)\n",
    "#Compute loss\n",
    "loss = losses(h, Y_test)\n",
    "print(\"Loss at test time : {}\".format(loss))\n",
    "print(\"Final weights : \",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss per epoch')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFpxj1M2iLpUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa07c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(n_epochs)),loss_epoch,'-r')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss per epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting thing to note in this program is the learning rate. It is kept unsually small. The reason for the small learning rate is influenced by weights initialization. The weights are initialized in a range close to what the actual real weights should be. Thus, only very tiny updates are needed over time to reach the goal. Interestingly, if the learning rate is 1e-8, then the network drastically converges. Any higher learning rate like say 1e-6 provides to much energy to the system that the values just overshoot. \n",
    "\n",
    "One can try different learning rates to witness some interesting plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
