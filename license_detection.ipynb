{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For Video and Image Processing\n",
    "import cv2\n",
    "#For Mathematical Operations\n",
    "import numpy as np\n",
    "#For Image to text Conversion\n",
    "import pytesseract\n",
    "import tesseract-ocr\n",
    "#For Data Manipulation\n",
    "import pandas as pd\n",
    "#For Regular Expression Operations\n",
    "import re\n",
    "#For Image Operations\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\VIVEK\\GitHubRepos\\tensorzone\n"
     ]
    }
   ],
   "source": [
    "#Path to current working directory\n",
    "cwd = os.getcwd()\n",
    "#Create directories\n",
    "os.mkdir(cwd+'\\\\datasets')\n",
    "os.mkdir(cwd+'\\\\img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input CSV: {frame,minX,maxX,minY,maxY,text}\n",
    "csvfile = \"\\\\datasets\\\\testcsv.csv\" \n",
    "#Input Video file of vehicles at toll\n",
    "videofile = '\\\\datasets\\\\test.mp4'\n",
    "#Regular Expression for a license plate\n",
    "search_pattern_re = r'[A-Z]{2}-[0-9]{2}-[A-Z]{1,2}-[0-9]{3,4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class VideoProcessor takes two input files : the csvfile and the videofile for input, and the regular\n",
    "#expression of the pattern to search. The basic purpose of the class is to process the videofile frame\n",
    "#by frame.For each frame it detect objects(contours). The contour search space is refined by the mid \n",
    "#points computed from the csvfile. Particularly, for multiple entries of each frame in csvfile a list \n",
    "#of mid points is computed. If any of these mid points exist within a specific contour then that \n",
    "#contour is a valid contour to search for license plate numbers. The idea is similar to region proposals \n",
    "#method used in R-CNN to define search spaces for object detection. The valid contour then undergoes an \n",
    "#affine transformation of -12.5 degrees to straighten the text that seems tilted due to camera angle. \n",
    "#This angle of -12.5 degrees was fixed through experimentation. Text in then detected in the \n",
    "#transformed contour. This text is searched for a match of regular expression. If a match is obtained, \n",
    "#then the match is appended to a list of license numbers detected in that frame =>\n",
    "#{frame:[list of license nos]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VideoProcessor(object):\n",
    "    \n",
    "    def __init__(self,csvfile,videofile,search_pattern_re):\n",
    "        self.csv_file = csvfile\n",
    "        self.video_file = videofile\n",
    "        self.reg_ex = search_pattern_re\n",
    "        self.final_dict = {}\n",
    "    \n",
    "    #Reads csv file\n",
    "    def _read_csv_data(self):\n",
    "        self.data = pd.read_csv(cwd + self.csv_file, index_col=0)\n",
    "        \n",
    "    #Compiles RegEx object    \n",
    "    def _reg_ex_compile(self):\n",
    "        self.reg = re.compile(self.reg_ex)\n",
    "        \n",
    "    #Detects contours in image    \n",
    "    def get_contours(self,image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray,100,200)\n",
    "        im2, contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return contours\n",
    "    \n",
    "    #Detects midpoints for data for each frame in csv\n",
    "    def get_mids(self,data):\n",
    "        mid_points = [[int((data.maxX[m]+data.minX[m])/2),int((data.maxY[m]+data.minY[m])/2)]\n",
    "                for m in range(len(data))\n",
    "        ]\n",
    "        return mid_points\n",
    "    \n",
    "    #Gets box coordinates of each contour\n",
    "    def get_box(self,contour):\n",
    "        x_axes = [contour[j][0][0] for j in range(len(contour))]\n",
    "        y_axes = [contour[j][0][1] for j in range(len(contour))]\n",
    "        min_x,min_y,max_x,max_y = np.min(x_axes),np.min(y_axes),np.max(x_axes),np.max(y_axes)\n",
    "        return {'min_x':min_x,\n",
    "                'min_y':min_y,\n",
    "                'max_x':max_x,\n",
    "                'max_y':max_y\n",
    "        }\n",
    "\n",
    "    #Calculates affine transformation for input image\n",
    "    def affine_transform(self,img,row,column,angle):\n",
    "        M = cv2.getRotationMatrix2D((column/2,row/2),angle,1)\n",
    "        trans_img = cv2.warpAffine(img,M,(column,row))\n",
    "        return trans_img\n",
    "    \n",
    "    #Returns text in image\n",
    "    def convert_to_text(self,img_arr):\n",
    "        inp = Image.fromarray(img_arr)\n",
    "        text = pytesseract.image_to_string(inp)\n",
    "        return text\n",
    "    \n",
    "    #Process video frame by frame for final output\n",
    "    def _process_video(self):\n",
    "        cap = cv2.VideoCapture(cwd + self.video_file)\n",
    "        i=0 #Frame index\n",
    "        while (cap.isOpened()):\n",
    "            self.final_dict.setdefault(i,[]) #Setting final data structure\n",
    "            ret, frame = cap.read() #Reading video frame by frame\n",
    "            contours = self.get_contours(frame) #detects contours in frame\n",
    "            temp = self.data[self.data.frame==i] #Slices dataframe where frame == i\n",
    "            size = len(temp) #Number of entries for each frame slice\n",
    "            temp.index = range(size) #Resets index of sliced dataframe from (0,size)\n",
    "            mids = self.get_mids(temp) #Computes mid points of sliced dataframe data\n",
    "            #Iterating over Each contour\n",
    "            for k,cont in enumerate(contours):\n",
    "                box = self.get_box(cont) #Box coordinates of each contour\n",
    "                #The condition either selects or rejects a contour\n",
    "                if (any(box['min_x']<=elem[0]<=box['max_x'] and box['min_y']<=elem[1]<=box['max_y'] for elem in mids)):\n",
    "                    #This is for refernce. Each contour image is saved based on box coordinates\n",
    "                    cv2.imwrite(cwd+'\\\\img\\\\cont-{}{}.jpg'.format(i,k),frame[box['min_y']:box['max_y'],\n",
    "                                                                             box['min_x']:box['max_x']])\n",
    "                    #Reading each valid contour image. We can get around this step\n",
    "                    im = cv2.imread(cwd+'\\\\img\\\\cont-{}{}.jpg'.format(i,k),0)\n",
    "                    r,c = im.shape #Shape of image\n",
    "                    trans_image = self.affine_transform(im,r,c,-12.25) #Image transformation\n",
    "                    text = self.convert_to_text(trans_image) #Return text in image\n",
    "                    text_lines = text.split('\\n') #For multi-line text, form a list of strings\n",
    "                    for string in textlines: #For each string\n",
    "                        #Search for RegEx match \n",
    "                        str_det = self.reg.search(string.lstrip().rstrip().replace(' ','-'))#Removing end spaces and replacing between spaces with '-'\n",
    "                        try:\n",
    "                            #Append matched string to final data structure\n",
    "                            self.final_dict[i].append(string[str_det.span(0):str_det.span(1)])\n",
    "                        except:\n",
    "                            continue\n",
    "                    #Purpose of a contour is done. We can remove that contour image             \n",
    "                    os.remove(cwd+'\\\\img\\\\cont-{}{}.jpg'.format(i,k))\n",
    "              \n",
    "            i+=1\n",
    "        cap.release()\n",
    "    \n",
    "    #Create csv of final data structure\n",
    "    def _create_csv(self):\n",
    "        pd.DataFrame(self.final_dict).to_csv(cwd+\"\\\\datasets\\\\output.csv\")\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    VP = VideoProcessor(csvfile,videofile,search_pattern_re)\n",
    "    VP._reg_ex_compile()\n",
    "    VP._read_csv_data()\n",
    "    VP._process_video()\n",
    "    VP._create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one has decent GPU access, there can be a similar alternate. One can train a Haar Cascade Classifier for license plate detection. Following the same thread of video processing, once the classifier detects license plate, that particular contour in which it was detected could be passed for a regular expression match. If that matches, then the region proposals from the csv file could be used to increase the confidence of detecting correct license plate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
