{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np        #For Mathematical Operations\n",
    "import tensorflow as tf   #For ML\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "import os #For fetching from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper class to generate random batch of different sequence lengths\n",
    "class Helper(object):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batch(self):\n",
    "        batch=[]\n",
    "        for _ in range(self.batch_size):\n",
    "            size = np.random.randint(low=10,high=20)\n",
    "            batch.append(np.random.randint(low=0,high=10,size=size))\n",
    "        max_len = np.max([len(seq) for seq in batch ])\n",
    "        return batch,max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "PAD = 0  #Padding at the end of each sequence\n",
    "EOS = 1  #Token indicating end of sequence\n",
    "n_batches = 3000 #Number of batches in epoch\n",
    "batch_size= 50 #Batch_size\n",
    "enc_vocab_size = 10 # vocab size for encoder inputs\n",
    "dec_vocab_size = enc_vocab_size*2 - 1\n",
    "embed_size = 20 #embedding size\n",
    "encoder_hidden_units = 20 #Number of encoder hidden units\n",
    "decoder_hidden_units = encoder_hidden_units*2 #Number of decoder hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define placeholders\n",
    "with tf.variable_scope('placeholders'):\n",
    "    encoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"encoder_inputs\")\n",
    "    decoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"decoder_inputs\")\n",
    "    decoder_targets = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                    name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define embeddings\n",
    "with tf.name_scope('embeddings'):\n",
    "    enc_embed_matrix = tf.Variable(tf.random_uniform((enc_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"enc_embed_matrix\")\n",
    "    dec_embed_matrix = tf.Variable(tf.random_uniform((dec_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"dec_embed_matrix\")\n",
    "    encoder_embeddings = tf.nn.embedding_lookup(enc_embed_matrix,encoder_inputs)\n",
    "    decoder_embeddings = tf.nn.embedding_lookup(dec_embed_matrix,decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define encoder\n",
    "with tf.variable_scope('encoder'):\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(encoder_hidden_units)\n",
    "    encoder_initial_state = encoder_cell.zero_state(batch_size,tf.float32)\n",
    "    ((encoder_outputs_fw,encoder_outputs_bw),\n",
    "     (encoder_states_fw,encoder_states_bw)) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                                cell_fw=encoder_cell,\n",
    "                                                cell_bw=encoder_cell,\n",
    "                                                inputs=encoder_embeddings,\n",
    "                                                initial_state_fw=encoder_initial_state,\n",
    "                                                initial_state_bw=encoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_final_states_c = tf.concat([encoder_states_fw.c,encoder_states_bw.c],1)\n",
    "encoder_final_states_h = tf.concat([encoder_states_fw.h,encoder_states_bw.h],1)\n",
    "encoder_final_states = LSTMStateTuple(c=encoder_final_states_c,\n",
    "                                     h=encoder_final_states_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat([encoder_outputs_fw,encoder_outputs_bw],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define decoder\n",
    "with tf.variable_scope('decoder'):\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_hidden_units)\n",
    "    decoder_initial_state = encoder_final_states\n",
    "    ((decoder_outputs_fw,decoder_outputs_bw),\n",
    "    (decoder_states_fw,decoder_states_bw)) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                            cell_fw=decoder_cell,\n",
    "                                            cell_bw=decoder_cell,\n",
    "                                            inputs=decoder_embeddings,\n",
    "                                            initial_state_fw=decoder_initial_state,\n",
    "                                            initial_state_bw=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_outputs = tf.concat([decoder_outputs_fw,decoder_outputs_bw],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.fully_connected(decoder_outputs,dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=decoder_logits,\n",
    "                                                 labels=tf.cast(tf.one_hot(decoder_targets,dec_vocab_size),\n",
    "                                                               tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    tf.summary.histogram('loss', loss)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = Helper(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next():\n",
    "    batch,max_len = helper.generate_batch()\n",
    "    encoder_inputs_ = [np.append(np.append(seq,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_inputs_ = [np.append(np.append([EOS],seq*2),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_targets_ = [np.append(np.append(seq*2,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    return {encoder_inputs:encoder_inputs_,\n",
    "           decoder_inputs:decoder_inputs_,\n",
    "           decoder_targets:decoder_targets_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.9513587951660156\n",
      "  sample 1:\n",
      "    input     > [2 3 4 6 1 0 8 3 4 6 6 2 0 4 1 6 2 1 0 0]\n",
      "    decoder input  > [ 1  4  6  8 12  2  0 16  6  8 12 12  4  0  8  2 12  4  0  0]\n",
      "    predicted > [18 15 15 15 12 15 15 12 15 12 12 12 12 12 12 12 12 12 12  7]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [0 9 5 6 9 1 7 4 3 4 2 3 1 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1  0 18 10 12 18  2 14  8  6  8  4  6  0  0  0  0  0  0  0]\n",
      "    predicted > [18 18  0  0 12 10 10 10 12 13 13 14 15 15 15 15  0  0  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [3 8 2 6 5 7 7 0 1 8 4 6 4 3 4 1 0 0 0 0]\n",
      "    decoder input  > [ 1  6 16  4 12 10 14 14  0  2 16  8 12  8  6  8  0  0  0  0]\n",
      "    predicted > [18  5  5 18  0  0 10 10 15 15  3 12 12 12 12 12 14 14 14 10]\n",
      "batch 1000\n",
      "  minibatch loss: 0.01646534726023674\n",
      "  sample 1:\n",
      "    input     > [ 4.  1.  3.  8.  5.  0.  4.  4.  9.  6.  7.  8.  7.  8.  9.  3.  3.  2.\n",
      "  2.  1.]\n",
      "    decoder input  > [  1.   8.   2.   6.  16.  10.   0.   8.   8.  18.  12.  14.  16.  14.  16.\n",
      "  18.   6.   6.   4.   4.]\n",
      "    predicted > [ 8  2  6 16 10  0  8  8 18 12 14 16 14 16 18  6  6  4  4  1]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [6 5 3 9 6 7 9 3 1 2 9 8 1 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1 12 10  6 18 12 14 18  6  2  4 18 16  0  0  0  0  0  0  0]\n",
      "    predicted > [12 10  6 18 12 14 18  6  2  4 18 16  1  0  0  0  0  0  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [9 1 6 8 2 1 7 4 0 1 1 7 1 6 0 1 1 0 0 0]\n",
      "    decoder input  > [ 1 18  2 12 16  4  2 14  8  0  2  2 14  2 12  0  2  0  0  0]\n",
      "    predicted > [18  2 12 16  4  2 14  8  0  2  2 14  2 12  0  2  1  0  0  0]\n",
      "batch 2000\n",
      "  minibatch loss: 0.0034091335255652666\n",
      "  sample 1:\n",
      "    input     > [2 9 1 3 3 8 0 3 1 1 5 1 0 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1  4 18  2  6  6 16  0  6  2  2 10  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 4 18  2  6  6 16  0  6  2  2 10  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [7 2 4 6 4 5 0 1 9 7 9 1 0 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1 14  4  8 12  8 10  0  2 18 14 18  0  0  0  0  0  0  0  0]\n",
      "    predicted > [14  4  8 12  8 10  0  2 18 14 18  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [0 2 3 5 0 0 6 4 7 7 3 5 1 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1  0  4  6 10  0  0 12  8 14 14  6 10  0  0  0  0  0  0  0]\n",
      "    predicted > [ 0  4  6 10  0  0 12  8 14 14  6 10  1  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "loss_sum = 0.0\n",
    "batches_in_epoch = 1000 \n",
    "saver = tf.train.Saver()\n",
    "#For tensorboard visualizations\n",
    "writer = tf.summary.FileWriter('/graphs/seq2seq2', sess.graph)\n",
    "#Check if checkpoint present \n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('/checkpoints/seq2seq2/checkpoint'))\n",
    "#Restore the latest checkpoint if present\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "try:\n",
    "    for batch in range(n_batches):\n",
    "        fd = next()\n",
    "        _, loss_val,summary = sess.run([optimizer, loss,summary_op], fd)\n",
    "        loss_sum += loss_val\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            sess.run(tf.shape(decoder_outputs),fd)\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(loss_val))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp,dec, pred) in enumerate(zip(fd[encoder_inputs],fd[decoder_inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    decoder input  > {}'.format(dec))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "                print()\n",
    "            saver.save(sess, '/checkpoints/seq2seq2/seq2seq2', batch)\n",
    "               \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
