{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np        #For Mathematical Operations\n",
    "import tensorflow as tf   #For ML\n",
    "import os #For fetching from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper class to generate random batch of different sequence lengths\n",
    "class Helper(object):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batch(self):\n",
    "        batch=[]\n",
    "        for _ in range(self.batch_size):\n",
    "            size = np.random.randint(low=5,high=8)\n",
    "            batch.append(np.random.randint(low=0,high=10,size=size))\n",
    "        max_len = np.max([len(seq) for seq in batch ])\n",
    "        return batch,max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "PAD = 0  #Padding at the end of each sequence\n",
    "EOS = 1  #Token indicating end of sequence\n",
    "n_batches = 3000 #Number of batches in epoch\n",
    "batch_size= 50 #Batch_size\n",
    "enc_vocab_size = 10 # vocab size for encoder inputs\n",
    "dec_vocab_size = enc_vocab_size*2 - 1\n",
    "embed_size = 20 #embedding size\n",
    "encoder_hidden_units = 20 #Number of encoder hidden units\n",
    "decoder_hidden_units = encoder_hidden_units #Number of decoder hidden units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define placeholders\n",
    "with tf.variable_scope('placeholders'):\n",
    "    encoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"encoder_inputs\")\n",
    "    decoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"decoder_inputs\")\n",
    "    decoder_targets = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                    name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define embeddings\n",
    "with tf.name_scope('embeddings'):\n",
    "    enc_embed_matrix = tf.Variable(tf.random_uniform((enc_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"enc_embed_matrix\")\n",
    "    dec_embed_matrix = tf.Variable(tf.random_uniform((dec_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"dec_embed_matrix\")\n",
    "    encoder_embeddings = tf.nn.embedding_lookup(enc_embed_matrix,encoder_inputs)\n",
    "    decoder_embeddings = tf.nn.embedding_lookup(dec_embed_matrix,decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define encoder\n",
    "with tf.variable_scope('encoder'):\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(encoder_hidden_units)\n",
    "    encoder_initial_state = encoder_cell.zero_state(batch_size,tf.float32)\n",
    "    encoder_outputs,encoder_states = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                       inputs=encoder_embeddings,\n",
    "                                                       initial_state=encoder_initial_state, \n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define decoder\n",
    "with tf.variable_scope('decoder'):\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_hidden_units)\n",
    "    decoder_initial_state = encoder_states\n",
    "    decoder_outputs,decoder_states = tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                                                      inputs=decoder_embeddings,\n",
    "                                                      initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores\n",
    "decoder_logits = tf.contrib.layers.fully_connected(decoder_outputs,dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax entropy for scores\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=decoder_logits,\n",
    "                                                 labels=tf.cast(\n",
    "                                                     tf.one_hot(decoder_targets,dec_vocab_size),\n",
    "                                                     tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoder predictions\n",
    "decoder_prediction = tf.argmax(decoder_logits,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define loss\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    tf.summary.histogram('loss', loss)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizer with default learning rate\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Helper object\n",
    "helper = Helper(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to generate inputs for training seq2seq\n",
    "def next():\n",
    "    batch,max_len = helper.generate_batch()\n",
    "    encoder_inputs_ = [np.append(np.append(seq,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_inputs_ = [np.append(np.append([EOS],seq*2),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_targets_ = [np.append(np.append(seq*2,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "#     print(encoder_inputs_,decoder_inputs_,decoder_targets_)\n",
    "    return {encoder_inputs:encoder_inputs_,\n",
    "           decoder_inputs:decoder_inputs_,\n",
    "           decoder_targets:decoder_targets_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.9244747161865234\n",
      "  sample 1:\n",
      "    input     > [ 2.  1.  5.  0.  9.  7.  4.  1.]\n",
      "    decoder input  > [  1.   4.   2.  10.   0.  18.  14.   8.]\n",
      "    predicted > [14 14 14 14 14 14 14 14]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [ 6.  8.  7.  0.  9.  2.  2.  1.]\n",
      "    decoder input  > [  1.  12.  16.  14.   0.  18.   4.   4.]\n",
      "    predicted > [14 14 14 14 14 14  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [ 5.  2.  9.  6.  8.  0.  1.  1.]\n",
      "    decoder input  > [  1.  10.   4.  18.  12.  16.   0.   2.]\n",
      "    predicted > [14 14 14 14 14 14 14 14]\n",
      "batch 1000\n",
      "  minibatch loss: 0.6424353122711182\n",
      "  sample 1:\n",
      "    input     > [7 0 5 6 4 1 0 0]\n",
      "    decoder input  > [ 1 14  0 10 12  8  0  0]\n",
      "    predicted > [ 0  0 10 12  8  1  0  0]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [3 3 7 2 4 8 1 0]\n",
      "    decoder input  > [ 1  6  6 14  4  8 16  0]\n",
      "    predicted > [ 6 16 14  4  8 16  1  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [8 5 0 3 5 1 0 0]\n",
      "    decoder input  > [ 1 16 10  0  6 10  0  0]\n",
      "    predicted > [16 10  0  6 10  1  0  0]\n",
      "batch 2000\n",
      "  minibatch loss: 0.2932537794113159\n",
      "  sample 1:\n",
      "    input     > [0 9 7 5 8 2 1 0]\n",
      "    decoder input  > [ 1  0 18 14 10 16  4  0]\n",
      "    predicted > [ 0 18 14 10  4  4  1  0]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [ 7.  0.  0.  9.  1.  5.  1.  1.]\n",
      "    decoder input  > [  1.  14.   0.   0.  18.   2.  10.   2.]\n",
      "    predicted > [14  0  0  2  2 10  2  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [5 4 0 3 7 1 0 0]\n",
      "    decoder input  > [ 1 10  8  0  6 14  0  0]\n",
      "    predicted > [10  8  0  6 14  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "loss_sum = 0.0\n",
    "batches_in_epoch = 1000 \n",
    "saver = tf.train.Saver()\n",
    "#For tensorboard visualizations\n",
    "writer = tf.summary.FileWriter('E:/VIVEK/GitHubRepos/tensorzone/graphs/seq2seq', sess.graph)\n",
    "#Check if checkpoint present \n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('E:/VIVEK/GitHubRepos/tensorzone/checkpoints/seq2seq/checkpoint'))\n",
    "#Restore the latest checkpoint if present\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "try:\n",
    "    for batch in range(n_batches):\n",
    "        fd = next()\n",
    "        _, loss_val,summary = sess.run([optimizer, loss,summary_op], fd)\n",
    "        loss_sum += loss_val\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(loss_val))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp,dec, pred) in enumerate(zip(fd[encoder_inputs],fd[decoder_inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    decoder input  > {}'.format(dec))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "                print()\n",
    "            saver.save(sess, 'E:/VIVEK/GitHubRepos/tensorzone/checkpoints/seq2seq/seq2seq1', batch)\n",
    "               \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
