{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np        #For Mathematical Operations\n",
    "import tensorflow as tf   #For ML\n",
    "import os #For fetching from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper class to generate random batch of different sequence lengths\n",
    "class Helper(object):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batch(self):\n",
    "        batch=[]\n",
    "        for _ in range(self.batch_size):\n",
    "            size = np.random.randint(low=5,high=8)\n",
    "            batch.append(np.random.randint(low=0,high=10,size=size))\n",
    "        max_len = np.max([len(seq) for seq in batch ])\n",
    "        return batch,max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "PAD = 0  #Padding at the end of each sequence\n",
    "EOS = 1  #Token indicating end of sequence\n",
    "n_batches = 3000 #Number of batches in epoch\n",
    "batch_size= 50 #Batch_size\n",
    "enc_vocab_size = 10 # vocab size for encoder inputs\n",
    "dec_vocab_size = enc_vocab_size*2 - 1\n",
    "embed_size = 20 #embedding size\n",
    "encoder_hidden_units = 20 #Number of encoder hidden units\n",
    "decoder_hidden_units = encoder_hidden_units #Number of decoder hidden units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define placeholders\n",
    "with tf.variable_scope('placeholders'):\n",
    "    encoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"encoder_inputs\")\n",
    "    decoder_inputs = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                   name=\"decoder_inputs\")\n",
    "    decoder_targets = tf.placeholder(shape=(batch_size,None),dtype=tf.int32,\n",
    "                                    name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define embeddings\n",
    "with tf.name_scope('embeddings'):\n",
    "    enc_embed_matrix = tf.Variable(tf.random_uniform((enc_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"enc_embed_matrix\")\n",
    "    dec_embed_matrix = tf.Variable(tf.random_uniform((dec_vocab_size,embed_size),-1,1),\n",
    "                               dtype=tf.float32,name=\"dec_embed_matrix\")\n",
    "    encoder_embeddings = tf.nn.embedding_lookup(enc_embed_matrix,encoder_inputs)\n",
    "    decoder_embeddings = tf.nn.embedding_lookup(dec_embed_matrix,decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define encoder\n",
    "with tf.variable_scope('encoder'):\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(encoder_hidden_units)\n",
    "    encoder_initial_state = encoder_cell.zero_state(batch_size,tf.float32)\n",
    "    encoder_outputs,encoder_states = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                       inputs=encoder_embeddings,\n",
    "                                                       initial_state=encoder_initial_state, \n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define decoder\n",
    "with tf.variable_scope('decoder'):\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_hidden_units)\n",
    "    decoder_initial_state = encoder_states\n",
    "    decoder_outputs,decoder_states = tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                                                      inputs=decoder_embeddings,\n",
    "                                                      initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scores\n",
    "decoder_logits = tf.contrib.layers.fully_connected(decoder_outputs,dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Softmax entropy for scores\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=decoder_logits,\n",
    "                                                 labels=tf.cast(\n",
    "                                                     tf.one_hot(decoder_targets,dec_vocab_size),\n",
    "                                                     tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoder predictions\n",
    "decoder_prediction = tf.argmax(decoder_logits,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define loss\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    tf.summary.histogram('loss', loss)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizer with default learning rate\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Helper object\n",
    "helper = Helper(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to generate inputs for training seq2seq\n",
    "def next():\n",
    "    batch,max_len = helper.generate_batch()\n",
    "    encoder_inputs_ = [np.append(np.append(seq,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_inputs_ = [np.append(np.append([EOS],seq*2),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "    decoder_targets_ = [np.append(np.append(seq*2,[EOS]),[PAD]*(max_len-len(seq))) for seq in batch]\n",
    "#     print(encoder_inputs_,decoder_inputs_,decoder_targets_)\n",
    "    return {encoder_inputs:encoder_inputs_,\n",
    "           decoder_inputs:decoder_inputs_,\n",
    "           decoder_targets:decoder_targets_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.949699640274048\n",
      "  sample 1:\n",
      "    input     > [4 6 8 7 7 7 7 5 3 4 9 6 8 2 2 8 9 1 0 0]\n",
      "    decoder input  > [ 1  8 12 16 14 14 14 14 10  6  8 18 12 16  4  4 16 18  0  0]\n",
      "    predicted > [ 8  3  2  5  6 17 17 17 12 17  5 17 12 11 17 17  5 17 17  5]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [6 1 9 0 1 5 3 7 9 4 5 5 5 6 3 1 0 0 0 0]\n",
      "    decoder input  > [ 1 12  2 18  0  2 10  6 14 18  8 10 10 10 12  6  0  0  0  0]\n",
      "    predicted > [11  8  7 12 12 15 15  0 17 12 17  0  0  0  0  0  0 14 14 14]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [ 6.  8.  8.  8.  3.  6.  4.  3.  1.  3.  8.  6.  7.  7.  8.  0.  9.  1.\n",
      "  1.  1.]\n",
      "    decoder input  > [  1.  12.  16.  16.  16.   6.  12.   8.   6.   2.   6.  16.  12.  14.  14.\n",
      "  16.   0.  18.   2.   2.]\n",
      "    predicted > [ 4  4  6  6  6  6  6  5  3 15  9 18  7  7 17  6  5 17  7  7]\n",
      "batch 1000\n",
      "  minibatch loss: 1.5652778148651123\n",
      "  sample 1:\n",
      "    input     > [8 6 2 7 5 7 8 5 8 6 1 5 2 1 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1 16 12  4 14 10 14 16 10 16 12  2 10  4  0  0  0  0  0  0]\n",
      "    predicted > [12 12 12 12 12 12 10 12 12 12  8  0  0  1  0  0  0  0  0  0]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [9 9 0 8 2 3 9 7 2 7 7 0 5 6 3 6 3 1 0 0]\n",
      "    decoder input  > [ 1 18 18  0 16  4  6 18 14  4 14 14  0 10 12  6 12  6  0  0]\n",
      "    predicted > [18 18 18 18 18 18 18 18 14 18  2 12 12 12  6 12  0  1  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [5 1 8 2 0 7 3 1 1 5 1 0 0 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1 10  2 16  4  0 14  6  2  2 10  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [10 10  2 18 18 18  0 12 12 10  1  0  0  0  0  0  0  0  0  0]\n",
      "batch 2000\n",
      "  minibatch loss: 1.4146959781646729\n",
      "  sample 1:\n",
      "    input     > [5 5 7 2 9 3 6 9 7 7 4 2 2 2 5 2 9 1 0 0]\n",
      "    decoder input  > [ 1 10 10 14  4 18  6 12 18 14 14  8  4  4  4 10  4 18  0  0]\n",
      "    predicted > [ 0  8 18 18 14 14 14 14  6  6  4 16 16 16 16  4  4  1  0  0]\n",
      "\n",
      "  sample 2:\n",
      "    input     > [8 3 1 3 8 1 4 2 5 4 1 0 0 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1 16  6  2  6 16  2  8  4 10  8  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [10  8 10  2 10  0  0 12 10  8  1  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "  sample 3:\n",
      "    input     > [2 1 7 1 2 1 2 9 8 7 6 2 1 0 0 0 0 0 0 0]\n",
      "    decoder input  > [ 1  4  2 14  2  4  2  4 18 16 14 12  4  0  0  0  0  0  0  0]\n",
      "    predicted > [ 4  2  4 16  4 16  4  4 16  4 16  4  1  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "loss_sum = 0.0\n",
    "batches_in_epoch = 1000 \n",
    "saver = tf.train.Saver()\n",
    "#For tensorboard visualizations\n",
    "writer = tf.summary.FileWriter('/graphs/seq2seq', sess.graph)\n",
    "#Check if checkpoint present \n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('/checkpoints/seq2seq/checkpoint'))\n",
    "#Restore the latest checkpoint if present\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "try:\n",
    "    for batch in range(n_batches):\n",
    "        fd = next()\n",
    "        _, loss_val,summary = sess.run([optimizer, loss,summary_op], fd)\n",
    "        loss_sum += loss_val\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(loss_val))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp,dec, pred) in enumerate(zip(fd[encoder_inputs],fd[decoder_inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    decoder input  > {}'.format(dec))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "                print()\n",
    "            saver.save(sess, '/checkpoints/seq2seq/seq2seq1', batch)\n",
    "               \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
